from enum import Enum
from typing import Any, Literal, Optional
from uuid import UUID

from pydantic import BaseModel, Field


def to_camel(snake_str: str) -> str:
    """Convert snake_case to camelCase"""
    components = snake_str.split("_")
    return components[0] + "".join(x.title() for x in components[1:])


class SchemaBase(BaseModel):
    class Config:
        populate_by_name = True
        alias_generator = to_camel


class Role(str, Enum):
    """Defines the role of the message author in a conversation."""

    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"


class FinishReason(str, Enum):
    """Reason why the generation stopped."""

    STOP = "stop"
    LENGTH = "length"
    CONTENT_FILTER = "content_filter"


class Message(SchemaBase):
    """A message in a conversation between user and assistant."""

    # The role of the message author
    role: Role

    # The content of the message
    content: str

    # Optional name identifying the message author
    name: Optional[str] = None


class GenerationOptions(SchemaBase):
    """Options that control the text generation process."""

    # The maximum number of tokens to generate
    max_tokens: Optional[int] = None

    # The number of tokens to sample from the top of the distribution
    temperature: Optional[float] = Field(None, ge=0.0, le=2.0)

    # Nucleus sampling parameter
    top_p: Optional[float] = Field(None, ge=0.0, le=1.0)

    # Sequences that will stop generation if encountered
    stop_sequences: Optional[list[str]] = None

    # Whether to return log probabilities of the generated tokens
    logprobs: Optional[bool] = None

    # The number of tokens to sample from the top of the distribution
    top_logprobs: Optional[int] = None

    # Extensions for the generation options
    extensions: Optional[dict[str, Any]] = Field(
        default=None, description="Container for specification extensions"
    )


class Usage(SchemaBase):
    """Token usage information for the request and response."""

    # The number of tokens in the prompt
    prompt_tokens: int

    # The number of tokens in the generated text
    completion_tokens: int

    # The total number of tokens used in the request and response
    total_tokens: int


class LogProbs(SchemaBase):
    """Log probabilities for generated tokens."""

    # Map of tokens to their log probabilities
    token_logprobs: dict[str, float] = Field(
        description="Map of tokens to their log probabilities"
    )


class ChatResponse(SchemaBase):
    """Response from a chat completion request."""

    # The ID of the response (using UUID instead of string)
    id: UUID

    # Name of the model used for generation
    model: str

    # The message generated by the assistant
    message: Message

    # Reason why the generation stopped
    finish_reason: Optional[FinishReason] = None

    # Token usage information
    usage: Usage

    # Provider-specific information
    provider_info: Optional[dict[str, Any]] = None

    # Log probabilities for generated tokens
    logprobs: Optional[LogProbs] = None


class GenerateChatParams(SchemaBase):
    """Parameters for chat completion generation."""

    # The model identifier to use for chat
    model: str

    # Array of message objects representing the conversation
    messages: list[Message]

    # Additional parameters for the generation
    options: Optional[GenerationOptions] = None


class EmbeddingOptions(SchemaBase):
    """Options for controlling document embedding process"""

    # Size of text chunks for embedding
    chunk_size: Optional[int] = Field(
        default=None, description="Size of text chunks for embedding"
    )

    # Overlap between consecutive chunks
    chunk_overlap: Optional[int] = Field(
        default=None, description="Overlap between consecutive chunks"
    )

    # Number of documents to process in a single batch
    batch_size: Optional[int] = Field(
        default=None, description="Number of documents to process in a single batch"
    )

    # Interval in seconds to check for new files
    process_interval: Optional[int] = Field(
        default=None, description="Interval in seconds to check for new files"
    )

    # Container for embedder-specific extensions
    extensions: Optional[dict[str, Any]] = Field(
        default=None, description="Container for embedder-specific extensions"
    )


class RetrievalOptions(SchemaBase):
    """Options for controlling document retrieval process"""

    # Maximum number of documents to retrieve
    limit: Optional[int] = Field(
        default=None, description="Maximum number of documents to retrieve"
    )

    # Minimum similarity score for retrieved documents
    similarity_threshold: Optional[float] = Field(
        default=None,
        description="Minimum similarity score for retrieved documents",
        ge=0,
        le=1,
    )

    # Whether to include document metadata in results
    include_metadata: Optional[bool] = Field(
        default=None, description="Whether to include document metadata in results"
    )

    # Whether to include vector embeddings in results
    include_embeddings: Optional[bool] = Field(
        default=None, description="Whether to include vector embeddings in results"
    )

    # Container for retriever-specific extensions
    extensions: Optional[dict[str, Any]] = Field(
        default=None, description="Container for retriever-specific extensions"
    )


class DocumentResult(SchemaBase):
    """A document retrieved from the index"""

    # Identifier for the document
    id: str = Field(..., description="Identifier for the document")

    # Similarity score between query and document
    score: float = Field(..., description="Similarity score between query and document")

    # Text content of the document or chunk
    content: str = Field(..., description="Text content of the document or chunk")

    # Metadata associated with the document
    metadata: Optional[dict[str, Any]] = Field(
        default=None, description="Metadata associated with the document"
    )

    # Vector embedding of the document (if requested)
    embedding: Optional[list[float]] = Field(
        default=None, description="Vector embedding of the document (if requested)"
    )


class EmbeddingResponse(SchemaBase):
    """The result of the document embedding operation"""

    # Unique identifier for this embedding operation
    id: UUID = Field(..., description="Unique identifier for this embedding operation")

    # Status of the embedding operation
    status: Literal["success", "partial_success", "failure"] = Field(
        ..., description="Status of the embedding operation"
    )

    # Number of documents successfully processed
    processed_count: int = Field(
        ..., description="Number of documents successfully processed"
    )

    # Number of documents that failed processing
    failed_count: Optional[int] = Field(
        default=None, description="Number of documents that failed processing"
    )

    # Router-specific information
    provider_info: Optional[dict[str, Any]] = Field(
        default=None, description="Router-specific information"
    )


class RetrievalResponse(SchemaBase):
    """The result of the document retrieval operation"""

    # Unique identifier for this retrieval operation
    id: UUID = Field(..., description="Unique identifier for this retrieval operation")

    # The original search query
    query: str = Field(..., description="The original search query")

    # Retrieved documents matching the query
    results: list[DocumentResult] = Field(
        ..., description="Retrieved documents matching the query"
    )

    # Router-specific information
    provider_info: Optional[dict[str, Any]] = Field(
        default=None, description="Router-specific information"
    )
